{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc3f309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a908bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8005116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44655747",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a48cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed2dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb837f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42d0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3acd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omd2l.data.StocksData import StocksData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243df055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0475aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./feat_alpha_df.pickle\", \"rb\") as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0067ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ff_alpha_direction'] = 1.0*(data['ff_alpha']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86079368",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [ \n",
    " 'px_rank',\n",
    " 'range',\n",
    " 'prior_ret',\n",
    " 'DollarVolume',\n",
    " 'Beta',\n",
    " 'SecBeta',\n",
    " 'market_relative_prior_ret',\n",
    " 'sector_relative_prior_ret' ]\n",
    "RESPONSE = ['ff_alpha_direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6bee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tradeDate'] = pd.to_datetime(data['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d810807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[FEATURES] = data.groupby('tradeDate')[FEATURES].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std())).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f5d614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['range'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4401ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StocksData(batch_size=1000,features=FEATURES, response=RESPONSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93caac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d67f7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23e1d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./feat_alpha_df.pickle\", \"rb\") as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "dataset['ff_alpha_direction'] = 1.0*(dataset['ff_alpha']>0)\n",
    "dataset['tradeDate'] = pd.to_datetime(dataset['date']).dt.date\n",
    "dataset.sort_values(by = 'tradeDate',ascending=True, inplace = True)\n",
    "dataset.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48db2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "520b22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13320be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegressionTabular(nn.Module):\n",
    "    def __init__(self, number_classes=2):\n",
    "        super().__init__()\n",
    "        self.net =  nn.LazyLinear(number_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y_pred = torch.sigmoid(self.net(X))\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5a34600",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" # torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b429fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10\n",
    "batch_size=128\n",
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7076e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "def loss_fn(Y_hat, Y, averaged=True):\n",
    "    Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "    Y = Y.reshape((-1,))\n",
    "    return F.cross_entropy(Y_hat, Y, reduction='mean' if averaged else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4782bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for train_data, train_labels in dataloader:\n",
    "\n",
    "        train_data, train_labels = train_data.to(device),train_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_data)\n",
    "        print(output)\n",
    "        loss = loss_fn(output,train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * train_data.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "#         train_correct += (predictions == train_labels).sum().item()\n",
    "        train_correct += np.diag(confusion_matrix(y_pred=predictions  , y_true =  train_labels ) ).sum()\n",
    "\n",
    "    return train_loss,train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bc90c66",
   "metadata": {},
   "outputs": [],
   "source": [
    " def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for validation_data, validation_labels in dataloader:\n",
    "            validation_data, validation_labels = validation_data.to(device),validation_labels.to(device)\n",
    "            output = model(validation_data)\n",
    "            loss=loss_fn(output,validation_labels)\n",
    "            valid_loss+=loss.item()*validation_data.size(0)\n",
    "            scores, predictions = torch.max(output.data,1)\n",
    "#             val_correct+=(predictions == validation_labels).sum().item()\n",
    "            val_correct+=np.diag(confusion_matrix(y_pred=predictions  , y_true =  validation_labels ) ).sum()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d91d9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>closeunadj</th>\n",
       "      <th>lastupdated</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_relative_prior_ret_250</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB-RF</th>\n",
       "      <th>HML-RF</th>\n",
       "      <th>RMW-RF</th>\n",
       "      <th>CMA-RF</th>\n",
       "      <th>RF</th>\n",
       "      <th>ff_alpha</th>\n",
       "      <th>ff_alpha_direction</th>\n",
       "      <th>tradeDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616915</th>\n",
       "      <td>PCH</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>45.52</td>\n",
       "      <td>46.370</td>\n",
       "      <td>45.26</td>\n",
       "      <td>46.05</td>\n",
       "      <td>473587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.05</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>683.380856</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-53.301433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616916</th>\n",
       "      <td>MCD</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>219.01</td>\n",
       "      <td>221.250</td>\n",
       "      <td>218.25</td>\n",
       "      <td>219.71</td>\n",
       "      <td>3816710.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.71</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>-1451.959187</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.766116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616917</th>\n",
       "      <td>PPG</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>146.40</td>\n",
       "      <td>148.090</td>\n",
       "      <td>145.89</td>\n",
       "      <td>147.93</td>\n",
       "      <td>1453805.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.93</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>-609.687509</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.162655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616918</th>\n",
       "      <td>HFC</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>25.28</td>\n",
       "      <td>26.385</td>\n",
       "      <td>24.71</td>\n",
       "      <td>25.80</td>\n",
       "      <td>2973595.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>-4179.360632</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.359212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616919</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>164.39</td>\n",
       "      <td>166.250</td>\n",
       "      <td>160.47</td>\n",
       "      <td>161.06</td>\n",
       "      <td>2249396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.06</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>1609.455428</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.145271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker        date    open     high     low   close     volume  \\\n",
       "616915    PCH  2020-11-24   45.52   46.370   45.26   46.05   473587.0   \n",
       "616916    MCD  2020-11-24  219.01  221.250  218.25  219.71  3816710.0   \n",
       "616917    PPG  2020-11-24  146.40  148.090  145.89  147.93  1453805.0   \n",
       "616918    HFC  2020-11-24   25.28   26.385   24.71   25.80  2973595.0   \n",
       "616919    ZTS  2020-11-24  164.39  166.250  160.47  161.06  2249396.0   \n",
       "\n",
       "        dividends  closeunadj lastupdated  ... sector_relative_prior_ret_250  \\\n",
       "616915        0.0       46.05  2020-11-24  ...                    683.380856   \n",
       "616916        0.0      219.71  2020-11-24  ...                  -1451.959187   \n",
       "616917        0.0      147.93  2020-11-24  ...                   -609.687509   \n",
       "616918        0.0       25.80  2020-11-24  ...                  -4179.360632   \n",
       "616919        0.0      161.06  2020-11-24  ...                   1609.455428   \n",
       "\n",
       "       Mkt-RF SMB-RF HML-RF  RMW-RF  CMA-RF   RF   ff_alpha  \\\n",
       "616915   1.56   0.48   2.76    0.53    0.54  0.0 -53.301433   \n",
       "616916   1.56   0.48   2.76    0.53    0.54  0.0  20.766116   \n",
       "616917   1.56   0.48   2.76    0.53    0.54  0.0 -19.162655   \n",
       "616918   1.56   0.48   2.76    0.53    0.54  0.0  34.359212   \n",
       "616919   1.56   0.48   2.76    0.53    0.54  0.0  45.145271   \n",
       "\n",
       "        ff_alpha_direction   tradeDate  \n",
       "616915                 0.0  2020-11-24  \n",
       "616916                 1.0  2020-11-24  \n",
       "616917                 0.0  2020-11-24  \n",
       "616918                 1.0  2020-11-24  \n",
       "616919                 1.0  2020-11-24  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb5ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35634359",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oualid/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 39\u001b[0m     train_loss, train_correct\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     test_loss, test_correct\u001b[38;5;241m=\u001b[39mvalid_epoch(model,device,test_loader,criterion)\n\u001b[1;32m     42\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_ids)\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m model(train_data)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[0;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "# # K-fold Cross Validation model evaluation\n",
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_data = dataset.iloc[train_ids,:]\n",
    "    test_data = dataset.iloc[test_ids,:]\n",
    "    \n",
    "#     data.x = data.x.to(torch.float)\n",
    "\n",
    "\n",
    "    \n",
    "    train_tensors = TensorDataset(torch.from_numpy(train_data[FEATURES].values).to(torch.float) ,  # X\n",
    "                                torch.from_numpy(train_data[RESPONSE].values).to(torch.float) )   # Y\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader( train_tensors,\n",
    "                                           batch_size=1000,\n",
    "                                           shuffle=True )\n",
    "    \n",
    "    test_tensors = TensorDataset(torch.from_numpy(test_data[FEATURES].values).to(torch.float) ,  # X\n",
    "                                torch.from_numpy(test_data[RESPONSE].values).to(torch.float) )   # Y\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader( test_tensors,\n",
    "                                           batch_size=1000,\n",
    "                                           shuffle=True )    \n",
    "\n",
    "    \n",
    "    model = SoftmaxRegressionTabular()\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "        test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n",
    "\n",
    "        train_loss = train_loss / len(train_ids)\n",
    "        train_acc = train_correct / len(train_ids) * 100\n",
    "        test_loss = test_loss / len(test_ids)\n",
    "        test_acc = test_correct / len(test_ids) * 100\n",
    "\n",
    "        print(f\"Epoch:{epoch + 1}/{num_epochs} AVG Training Loss:{train_loss} AVG Test Loss:{test_loss} AVG Training Acc {train_acc}   AVG Test Acc {test_acc}\" )\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5927eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a7535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7ac84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "# # K-fold Cross Validation model evaluation\n",
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_data = dataset.iloc[train_ids,:]\n",
    "    test_data = dataset.iloc[test_ids,:]\n",
    "    \n",
    "#     data.x = data.x.to(torch.float)\n",
    "\n",
    "\n",
    "    \n",
    "    train_tensors = TensorDataset(torch.from_numpy(train_data[FEATURES].values).to(torch.float) ,  # X\n",
    "                                torch.from_numpy(train_data[RESPONSE].values).to(torch.long) )   # Y\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader( train_tensors,\n",
    "                                           batch_size=1000,\n",
    "                                           shuffle=True )\n",
    "    \n",
    "    test_tensors = TensorDataset(torch.from_numpy(test_data[FEATURES].values).to(torch.float) ,  # X\n",
    "                                torch.from_numpy(test_data[RESPONSE].values).to(torch.long) )   # Y\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader( test_tensors,\n",
    "                                           batch_size=1000,\n",
    "                                           shuffle=True )    \n",
    "\n",
    "    \n",
    "    model = SoftmaxRegressionTabular()\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "#         train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "        train_loss, train_correct=0.0,0\n",
    "        model.train()\n",
    "        for train_data, train_labels in train_loader:\n",
    "\n",
    "            train_data, train_labels = train_data.to(device),train_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data)\n",
    "            loss = loss_fn(output,train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * train_data.size(0)\n",
    "            scores, predictions = torch.max(output.data, 1)\n",
    "            train_correct += np.diag(confusion_matrix(y_pred=predictions  , y_true =  train_labels ) ).sum()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f952a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correct/len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8966df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loss, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326003da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions == train_labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbabbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions == np.array([ item[0] for item in train_labels.tolist()]) ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions == np.array([ item[0] for item in train_labels.tolist()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d9b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16404c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a261ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred=predictions.tolist() , y_true =[ item[0] for item in train_labels.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf453a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8d700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
